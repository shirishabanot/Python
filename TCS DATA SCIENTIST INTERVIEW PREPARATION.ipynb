{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a8892f-2a7d-487c-a189-47e8324e4234",
   "metadata": {},
   "source": [
    "## Q. What is logistic regression assumptions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ec78d",
   "metadata": {},
   "source": [
    "A:--.independence of errors, \n",
    "linearity in the logit for continuous variables, \n",
    "absence of multicollinearity, \n",
    "and lack of strongly influential outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf68ee60",
   "metadata": {},
   "source": [
    "## Q.What are Assumptions of Linear Regression?\n",
    "\n",
    "### 6 Assumptions of linear regression include?:\n",
    "\n",
    "#### 1.Linearity: \n",
    "The relationship between the dependent and independent variables is linear.\n",
    "#### 2.Independence: \n",
    "The observations are independent of each other.\n",
    "#### 3.Homoscedasticity: \n",
    "The variance of the errors is constant across all levels of the independent variables.\n",
    "#### 4.Normality:\n",
    "The errors follow a normal distribution.\n",
    "#### 5.No multicollinearity:\n",
    "The independent variables are nothighly correlated with each other.\n",
    "#### 6.No endogeneity: \n",
    "There is no relationship between the errors and the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ace85d",
   "metadata": {},
   "source": [
    "## Assumptions of Linear Regression\n",
    "1.Linear Model\n",
    "\n",
    "2.No Multicolinearlity in the data\n",
    "\n",
    "3.Homoscedasticity of Residuals or Equal Variances\n",
    "\n",
    "4.No Autocorrelation in residuals\n",
    "\n",
    "5.Number of observations Greater than the number of predictors\n",
    "\n",
    "6.Each observation is unique\n",
    "\n",
    "7.Predictors are distributed Normally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e7892",
   "metadata": {},
   "source": [
    "## How to find out the  onwatend columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc7cd0",
   "metadata": {},
   "source": [
    "A:--.generate a power set of the dataframe columns and check if the columns set is duplicated all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154babb",
   "metadata": {},
   "source": [
    "## 1.What is the diffrence between supervised learning and unsupervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d4c59",
   "metadata": {},
   "source": [
    "Supervised learning involves training a model on a labeled dataset, meaning that each training example is paired with an output label. The goal is to learn a mapping from inputs to outputs. Common algorithms include linear regression, logistic regression, and support vector machines.\n",
    "\n",
    "Unsupervised learning, on the other hand, deals with unlabeled data. The goal is to infer the natural structure present within a set of data points. Common algorithms include k-means clustering, hierarchical clustering, and principal component analysis (PCA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3dfd2-1e33-437b-b5c5-b3a738f75302",
   "metadata": {},
   "source": [
    "## 2. How do you handle missing data in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e7170-599a-48b1-9c77-1a1a12a3a535",
   "metadata": {},
   "source": [
    "### Handling missing data can be approached in several ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4445b-1875-4217-a1e9-62d2db9237cf",
   "metadata": {},
   "source": [
    " 1. Deletion: Remove rows or columns with missing values. This is only advisable if the amount of missing data is small.\n",
    " 2. Imputation: Fill in missing values using statistical methods such as mean, median, or mode for numerical data, or the most frequent value for categorical data.\n",
    " 3. Prediction: Use machine learning algorithms to predict the missing values based on other available data.\n",
    " 4. Flagging: Create a new feature that indicates whether the data was missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57490bc-9868-40b6-ac10-cefa2a18e5f9",
   "metadata": {},
   "source": [
    "## 3. What is overfitting and how can you prevent it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b26cbd",
   "metadata": {},
   "source": [
    "Overfitting occurs when a model learns the training data too well, capturing noise and outliers, which negatively impacts its performance on new, unseen data. To prevent overfitting, you can:\n",
    "1. Use more training data: More data can help the model generalize better.\n",
    "2. Simplify the model: Reduce the complexity of the model by decreasing the number of features or parameters.\n",
    "3. Regularization: Apply techniques like L1 (Lasso) or L2 (Ridge) regularization to penalize large coefficients.\n",
    "4. Cross-validation: Use techniques like k-fold cross-validation to ensure the model performs well on different subsets of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40df0bf-70d7-4e49-8294-96523e3f6d3e",
   "metadata": {},
   "source": [
    "## 4. What is the difference between bagging and boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7172e42",
   "metadata": {},
   "source": [
    "Bagging (Bootstrap Aggregating) and boosting are both ensemble techniques used to improve the performance of machine learning models.\n",
    "\n",
    "Bagging:\n",
    "- Involves training multiple models independently on different subsets of the data and then averaging their predictions.\n",
    "- Reduces variance and helps in preventing overfitting.\n",
    "- Example: Random Forest.\n",
    "\n",
    "Boosting:\n",
    "- Involves training models sequentially, where each new model focuses on correcting the errors made by the previous ones.\n",
    "- Reduces bias and variance, often leading to better performance but can be prone to overfitting.\n",
    "- Example: Gradient Boosting, AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437858b-1ad8-4e9a-b260-753c1c705b40",
   "metadata": {},
   "source": [
    "## 5. Explain the concept of cross-validation and why it is important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25fb5c",
   "metadata": {},
   "source": [
    "Cross-validation is a technique used to assess the generalizability of a machine learning model.\n",
    "It involves partitioning the data into subsets, training the model on some subsets (training set), and validating it on the remaining subsets\n",
    "(validation set). The most common form is k-fold cross-validation, where the data is divided into k equally sized folds,\n",
    "and the model is trained and validated k times, each time using a different fold as the validation set and the remaining folds as the training set.\n",
    "\n",
    "Cross-validation is important because it provides a more reliable estimate of model performance by ensuring that the model is tested on different\n",
    "subsets of the data, reducing the risk of overfitting and providing a better understanding of how the model will perform on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2e919-55e4-439d-9615-ad61ab603374",
   "metadata": {},
   "source": [
    "# wipro Data Scientist for fresher interview questions..!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952cebde-f9e5-461c-908b-f2da89b3d962",
   "metadata": {},
   "source": [
    "## 1. Python or R – Which one would you prefer for text analytics?\n",
    "Python would be the best option because it has Pandas library that provides easy to use data structures and high-performance data analysis tools. R is more suitable for machine learning than just text analysis. Python performs faster for all types of text analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623a1d5-8de9-478b-9458-9a6beebc36c8",
   "metadata": {},
   "source": [
    "## 2. Differentiate between univariate, bivariate and multivariate analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630bdb19",
   "metadata": {},
   "source": [
    "Univariate statistics summarize only one variable at a time.For example, data collected from a sensor measuring the temperature of a room every second. \n",
    "Bivariate statistics compare two variables. Multivariate statistics compare more than two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc582c2-837d-4005-af85-b9b8bf82f6dd",
   "metadata": {},
   "source": [
    "## 3. Define some key performance indicators for the product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27253d49",
   "metadata": {},
   "source": [
    "Key performance indicators (KPIs) measure a company’s success versus a set of targets, objectives, or industry peers.\n",
    "KPIs can be financial, including net profit (or the bottom line, gross profit margin), revenues minus certain expenses, or the current ratio (liquidity and cash availability)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff257a-439c-4edd-946c-97139819c410",
   "metadata": {},
   "source": [
    "## 4. Which technique is used to predict categorical responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b2384",
   "metadata": {},
   "source": [
    "ANOVA, or analysis of variance, is to be used when the target variable is continuous and the dependent variables are categorical. \n",
    "Predictive model can be developed to predict the Survived feature. \n",
    "Categorical predictors are represented using 0 and 1 for dichotomous variables or using indicator (or dummy) variables for ordinal or categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c5388-c261-4c1b-b501-2b7fadd6b1e4",
   "metadata": {},
   "source": [
    "## 5. What is logistic regression? Or State an example when you have used logistic regression recently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73cda61",
   "metadata": {},
   "source": [
    "Logistic regression is a statistical analysis method used to predict a data value based on prior observations of a data set.\n",
    "Logistic Regression is used when the dependent variable (target) is categorical. \n",
    "For example: To predict whether an email is spam (1) or (0) whether the tumor is malignant (1) or not (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7650482d-7e87-4a83-a351-80f3ea103510",
   "metadata": {},
   "source": [
    "## 6. What are Recommender Systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7aed3d",
   "metadata": {},
   "source": [
    "Recommender systems are tools designed for interacting with large and complex information spaces and \n",
    "prioritizing items in these spaces that are likely to be of interest to the user.\n",
    "    The recommender system deals with a large volume of information present by filtering the most important information based on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1f883-f008-4102-8945-8bf91cb4b272",
   "metadata": {},
   "source": [
    "## 7. Why data cleaning plays a vital role in analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43881dea",
   "metadata": {},
   "source": [
    "Data cleaning, or data cleansing, is an important part of the process involved in preparing data for analysis.\n",
    "Data cleaning can help in analysis because: Cleaning data from multiple sources helps to transform it into a format that data analysts or data scientists can work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f633ffd2-81b8-4bfe-b29f-21829cf4cecd",
   "metadata": {},
   "source": [
    "## 8. What does NLP stand for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19259a3",
   "metadata": {},
   "source": [
    "NLP stands for Natural Language Processing which means a computer programs that either understand or generate speech or text.\n",
    "It is a sub-field of artificial intelligence, and regularly makes use of machine learning techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8853be-5c0a-494b-89a3-30468ddab5a4",
   "metadata": {},
   "source": [
    "## 9. What do you understand by the term Normal Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8dd55",
   "metadata": {},
   "source": [
    "A normal distribution is a common probability distribution and has a shape often referred to as a “bell curve.” \n",
    "Many everyday data sets typically follow a normal distribution: for example, the heights of adult humans, \n",
    "the scores on a test given to a large class, errors in measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed25498c-ca25-4968-b055-f6342c697762",
   "metadata": {},
   "source": [
    "## 10. Explain Cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e9ce0",
   "metadata": {},
   "source": [
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample. \n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. \n",
    "As such, the procedure is often called k-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded09b93-8c9f-49c1-af41-b454db523f07",
   "metadata": {},
   "source": [
    "## 11. How do you define data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed68a10",
   "metadata": {},
   "source": [
    "Data Science is a combination of algorithms, tools, and machine learning technique\n",
    "which helps you to find common hidden patterns from the given raw data.\n",
    "1Data science encompasses preparing data for analysis, including cleansing, aggregating, and manipulating the data to perform advanced data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10af4a-8aea-4c5a-b61e-bed54d744df1",
   "metadata": {},
   "source": [
    "## 12. What is meant by supervised and unsupervised learning in data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8511a14f",
   "metadata": {},
   "source": [
    "Supervised learning algorithms are trained using labeled data.\n",
    "In supervised learning, input data is provided to the model along with the output\n",
    "Unsupervised learning algorithms are trained using unlabeled data. Unsupervised learning model finds the hidden patterns in data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f423531d-e935-4084-a929-aa1e9636c5e7",
   "metadata": {},
   "source": [
    "## 13. What are the variants of Back Propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec01062a",
   "metadata": {},
   "source": [
    "The most common technique used to train a neural network is the back-propagation algorithm.\n",
    "There are three main variations of back-propagation: stochastic (also called online), batch and mini-batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71434ea1-d7d6-44c2-9ce2-c82d7ab6f04c",
   "metadata": {},
   "source": [
    "## 14. What is a Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a7929",
   "metadata": {},
   "source": [
    "Random forest is a supervised learning algorithm. The “forest” it builds, is an ensemble of decision trees, usually trained with the “bagging” method. \n",
    "The general idea of the bagging method is that a combination of learning models increases the overall result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b0577-5a10-4018-8064-dc7d03d5fd19",
   "metadata": {},
   "source": [
    "## 15. What is Collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc0754",
   "metadata": {},
   "source": [
    "Collaborative filtering (CF) is a technique used by recommender systems. \n",
    "It is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea8088-e882-4fa3-959c-6f723fcbf117",
   "metadata": {},
   "source": [
    "## 16. What is Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83b51f",
   "metadata": {},
   "source": [
    "Linear Regression is a linear model that assumes a linear relationship between input variables (independent variables ‘x’)\n",
    "and output variable (dependent variable-‘y’) such that ‘y’ can be calculated from a linear combination of input variables(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdf6b6-05b9-4606-bf92-7482a15451b7",
   "metadata": {},
   "source": [
    "## 17. What is Interpolation and Extrapolation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62100a",
   "metadata": {},
   "source": [
    "When we predict values that fall within the range of data points taken it is called interpolation. \n",
    "When we predict values for points outside the range of data taken it is called extrapolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d8ded9-a1e5-40bd-969f-a343b1a8e2ea",
   "metadata": {},
   "source": [
    "## 18. What is power analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435eb356",
   "metadata": {},
   "source": [
    "Statistical power is the probability of a hypothesis test of finding an effect if there is an effect to be found.\n",
    "A power analysis can be used to estimate the minimum sample size required for an experiment, given a desired significance level, effect size, and statistical power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007c960-ce64-4adf-9393-4d2dd4743492",
   "metadata": {},
   "source": [
    "## 19. What is the difference between Cluster and Systematic Sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6b9dd",
   "metadata": {},
   "source": [
    "Systematic sampling selects a random starting point from the population, \n",
    "and then a sample is taken from regular fixed intervals of the population depending on its size.\n",
    "Cluster sampling divides the population into clusters and then takes a simple random sample from each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d00a3-975e-42bc-8b9b-1e188ba40ff4",
   "metadata": {},
   "source": [
    "## 20. Are expected value and mean value different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b5ad2",
   "metadata": {},
   "source": [
    "Expected values and mean value are same.\n",
    "To find the expected value, E(X), or mean μ of a discrete random variable X, simply multiply each value of the random variable by its probability and add the products. \n",
    "The formula is given as. E ( X ) = μ = ∑ x P ( x )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc715c82-ff92-41fa-b78c-a7b0b3dc44bf",
   "metadata": {},
   "source": [
    "## 21. What does P-value signify about the statistical data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b12b96",
   "metadata": {},
   "source": [
    "In statistics, the p-value is the probability of obtaining results at least as extreme as the observed results of a statistical hypothesis test, \n",
    "assuming that the null hypothesis is correct. A smaller p-value means that there is stronger evidence in favor of the alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812900b5-2df5-4b87-b01a-9c90c3af0c81",
   "metadata": {},
   "source": [
    "## 22. How you can make data normal using Box-Cox transformation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dbacb9",
   "metadata": {},
   "source": [
    "The statisticians George Box and David Cox developed a procedure to identify an appropriate exponent (Lambda = l) \n",
    "to use to transform data into a “normal shape.” The Lambda value indicates the power to which all data should be raised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c94d1-1ffc-4cc0-9b65-701ae085b3fd",
   "metadata": {},
   "source": [
    "## 23. What is the goal of A/B Testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2947c992",
   "metadata": {},
   "source": [
    "A/B testing is a basic randomized control experiment \n",
    "which is a way to compare the two versions of a variable to find out which performs better in a controlled environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0a2d7-162c-48dc-b779-8b8de18690bb",
   "metadata": {},
   "source": [
    "## 24. What is an Eigenvalue and Eigenvector?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6885a03e",
   "metadata": {},
   "source": [
    "Eigenvectors are unit vector that represent their length or magnitude is equal to 1. They are often referred to as right vectors which mean a column vector. \n",
    "Whereas, eigenvalues are coefficients applied to eigenvectors that give the vectors their length or magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86957111-3960-45dd-9ca6-b64e9abe4315",
   "metadata": {},
   "source": [
    "## 25. What is Gradient Descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505bb95",
   "metadata": {},
   "source": [
    "Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. \n",
    "The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, \n",
    "because this is the direction of steepest descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50725352-ff36-4dec-b767-5826f2e307a1",
   "metadata": {},
   "source": [
    "## 26. Do gradient descent methods always converge to same point?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54dfd9",
   "metadata": {},
   "source": [
    "Not always. In gradient descent, it depends on where you start (initialize). \n",
    "It is very easy to get stuck in local minima. So if you start from the same point for each solution, it will converge to the same minima.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6fb8fa-8fb9-412b-bd0e-b5617e613c43",
   "metadata": {},
   "source": [
    "## 27. What are various steps involved in an analytics project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dbc5bc",
   "metadata": {},
   "source": [
    "Data Preparation.\n",
    "Data Modelling.\n",
    "Validation.\n",
    "Implementation of the Model and Tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57e2a2",
   "metadata": {},
   "source": [
    "## 28. What are the basic assumptions to be made for linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8ad427",
   "metadata": {},
   "source": [
    "Four assumptions are associated with a linear regression model:\n",
    "    \n",
    "Linearity: \n",
    "    The relationship between X and the mean of Y is linear. \n",
    "Homoscedasticity: \n",
    "    The variance of residual is the same for any value of X. Independence: \n",
    "        Observations are independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc7dfc-e2e7-420d-8992-88a1951df0da",
   "metadata": {},
   "source": [
    "## 29. How will you assess the statistical significance of an insight whether it is a real insight or just by chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6e552",
   "metadata": {},
   "source": [
    "Statistical significance is often calculated with statistical hypothesis testing, \n",
    "which tests the validity of a hypothesis by figuring out the probability that your results have happened by chance.\n",
    "The level at which one can accept whether an event is statistically significant is known as the significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6980ce9-ae60-4a10-a72b-98b5c47a4167",
   "metadata": {},
   "source": [
    "# ACCENTUURE DATA SCIENCE INTERVIEW QUESTIONS FOR FRESHERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69614d6-bd3d-436f-9a1a-030c208cc683",
   "metadata": {},
   "source": [
    "## 1. How can you assess a good logistic model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bca4de",
   "metadata": {},
   "source": [
    "Likelihood Ratio Test and Pseudo R^2.\n",
    "Hosmer-Lemeshow, Wald Test.\n",
    "Variable Importance, Classification Rate.\n",
    "ROC Curve, K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c314c-46db-4165-b020-70de3b908c79",
   "metadata": {},
   "source": [
    "## 2. What are various steps involved in an analytics project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2454ff",
   "metadata": {},
   "source": [
    "\n",
    "Find an Interesting Topic followed by obtain and understand Data.\n",
    "Data Preparation and data modelling.\n",
    "Model Evaluation.\n",
    "Deployment and Visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b340f-20f9-4ab6-8e7e-780a3424f7e2",
   "metadata": {},
   "source": [
    "## 3. During analysis, how do you treat missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d47b1f",
   "metadata": {},
   "source": [
    "Deleting Rows with missing values.\n",
    "Impute missing values for continuous variable and categorical variable.\n",
    "Other Imputation Methods.\n",
    "Using Algorithms that support missing values with prediction of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531311d-c769-46ce-b95b-fc991df5ca12",
   "metadata": {},
   "source": [
    "## 4. Explain about the box cox transformation in regression models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9080c1",
   "metadata": {},
   "source": [
    "A Box Cox transformation is a transformation of non-normal dependent variables into a normal shape. \n",
    "Normality is an important assumption for many statistical techniques; if your data isn’t normal, \n",
    "applying a Box-Cox means that you are able to run a broader number of tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6fa995-bab5-4f67-b271-7e29919d43ee",
   "metadata": {},
   "source": [
    "## 5. Can you use machine learning for time series analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a049803",
   "metadata": {},
   "source": [
    "Time series forecasting is an important area of machine learning that is often neglected. \n",
    "It is important because there are so many prediction problems that involve a time component. \n",
    "Standard definitions of time series, time series analysis, and time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88c16f-b4be-41cc-8f6d-8ac75725a894",
   "metadata": {},
   "source": [
    "## 6. Write a function that takes in two sorted lists and outputs a sorted list that is their union."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbfc6e",
   "metadata": {},
   "source": [
    "Take in the number of elements for the first list and store it in a variable.\n",
    "Take in the elements of the list one by one.\n",
    "Similarly, take in the elements for the second list also.\n",
    "Merge both the lists using the ‘+’ operator and then sort the list.\n",
    "Display the elements in the sorted list.\n",
    "Exit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db635a6-5f78-4daf-8ff3-0635f5fe12ed",
   "metadata": {},
   "source": [
    "## 7. What is Regularization and what kind of problems does regularization solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f16583",
   "metadata": {},
   "source": [
    "Overfitting is a phenomenon that occurs when a Machine Learning model is constraint to training set and not able to perform well on unseen data. \n",
    "Regularization is a technique used to reduce the errors by fitting the function appropriately on the given training set and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32e6f2-91e7-4865-a6cf-056f0526ce4f",
   "metadata": {},
   "source": [
    "## 8. What is multicollinearity and how you can overcome it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3fed2",
   "metadata": {},
   "source": [
    "Multicollinearity occurs when independent variables in a regression model are correlated. \n",
    "This correlation is a problem because independent variables should be independent. \n",
    "If the degree of correlation between variables is high enough, it can cause problems when you fit the model and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813cac5-462a-4cf1-b214-ad0fe788be1f",
   "metadata": {},
   "source": [
    "## 9. What is the curse of dimensionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76879c85",
   "metadata": {},
   "source": [
    "The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces that \n",
    "do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298748b2-9d31-4491-8ce7-9231fdbbc7a7",
   "metadata": {},
   "source": [
    "## 10. How do you decide whether your linear regression model fits the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c83e5",
   "metadata": {},
   "source": [
    "Make sure the assumptions are satisfactorily met.\n",
    "Examine potential influential point, the change in R2 and Adjusted R2 statistics.\n",
    "Check necessary interaction and apply the model to another data set and check its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ac80f-0c20-4d04-80a5-856f37d5a439",
   "metadata": {},
   "source": [
    "## 11. What is Data Science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c710685f",
   "metadata": {},
   "source": [
    "Data science is the field of study that combines domain expertise, programming skills, and knowledge of mathematics and \n",
    "statistics to extract meaningful insights from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360bc16b-8338-44fa-a592-513879b15f9a",
   "metadata": {},
   "source": [
    "## 12. What is the Law of Large Numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b14c3a3",
   "metadata": {},
   "source": [
    "The law of large numbers is a theorem from probability and statistics that suggests that the average result from \n",
    "repeating an experiment multiple times will better approximate the true or expected underlying result.\n",
    "All sample observations for an experiment are drawn from an idealized population of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a12458-00bf-4ddc-9d99-523886392c6d",
   "metadata": {},
   "source": [
    "## 13. How Machine Learning Is Deployed In Real World Scenarios?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46ca21",
   "metadata": {},
   "source": [
    "Deployment is the method by which you integrate a machine learning model into an existing production environment \n",
    "to make practical business decisions based on data. It is one of the last stages in the machine learning life cycle \n",
    "and can be one of the most cumbersome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1d09c-e593-48a2-ba31-01714a414403",
   "metadata": {},
   "source": [
    "## 14. What is collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc621ac",
   "metadata": {},
   "source": [
    "Collaborative filtering uses a large set of data about user interactions to generate a set of recommendations. \n",
    "The idea behind collaborative filtering is that users with similar evaluations of certain items will \n",
    "enjoy the same things both now and in the future. User preference data can also be gathered implicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e2209-b297-479e-8f95-f1f466f0c424",
   "metadata": {},
   "source": [
    "## 15. What are the important libraries of Python that are used in Data Science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ffffd",
   "metadata": {},
   "source": [
    "TensorFlow,\n",
    "NumPy.\n",
    "SciPy, \n",
    "Matplotlib.\n",
    "Pandas,\n",
    "Keras.\n",
    "SciKit-Learn,\n",
    "Statsmodels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7988ff-ef53-4c3f-90c7-ae66f197ed66",
   "metadata": {},
   "source": [
    "## 16. What is the difference between squared error and absolute error?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb71ea",
   "metadata": {},
   "source": [
    "The magnitude of the difference between the individual measurement and the true value of the quantity is called the absolute error of the measurement. \n",
    "The arithmetic mean of all the absolute error is taken as the mean absolute error of the value of the physical quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8bfdb-1cb0-4849-9b48-15caf41a9136",
   "metadata": {},
   "source": [
    "## 17. What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecdf88a",
   "metadata": {},
   "source": [
    "Machine-learning algorithms use statistics to find patterns in massive amounts of data. \n",
    "And data, here, encompasses a lot of things—numbers, words, images, clicks, what have you. \n",
    "If it can be digitally stored, it can be fed into a machine-learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06174d94-317f-46c8-9d11-af50d41aa854",
   "metadata": {},
   "source": [
    "## 18. How are confidence intervals constructed and how will you interpret them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa963ac",
   "metadata": {},
   "source": [
    "A confidence interval displays the probability that a parameter will fall between a pair of values around the mean. \n",
    "Confidence intervals measure the degree of uncertainty or certainty in a sampling method. \n",
    "They are most often constructed using confidence levels of 95% or 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa56e67-c451-44d3-82a8-1f7cb71ef48a",
   "metadata": {},
   "source": [
    "## 19. How will you explain logistic regression to an economist, physican scientist and biologist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940d78f",
   "metadata": {},
   "source": [
    "Logistic regression is a statistical analysis method used to predict a data value based on prior observations of a data set. \n",
    "A logistic regression model predicts a dependent data variable by analyzing the relationship between one or more existing independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296bffa7-957e-479b-afa7-2202257c6c03",
   "metadata": {},
   "source": [
    "## 20. How can you overcome Overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69025a",
   "metadata": {},
   "source": [
    "Cross-validation and train with more data.\n",
    "Remove features and early stopping.\n",
    "Regularization, ensembling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f07bb-9035-4841-a2f0-48a1313cfe6d",
   "metadata": {},
   "source": [
    "## 21. Differentiate between wide and tall data formats?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683c206",
   "metadata": {},
   "source": [
    "Wide data has a column for each variable whereas long format data has a column for possible variable types & \n",
    "a column for the values of those variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70919f-0695-43f0-8d58-2c6cab2166f4",
   "metadata": {},
   "source": [
    "## 22. Is Naïve Bayes bad? If yes, under what aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00254c02",
   "metadata": {},
   "source": [
    "One of the disadvantages of Naïve-Bayes is that if you have no occurrences of a class label and a certain attribute value \n",
    "together then the frequency-based probability estimate will be zero. And this will get a zero when all the probabilities are multiplied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557be7b-673b-47b1-b221-39025ce0399e",
   "metadata": {},
   "source": [
    "## 23. How would you develop a model to identify plagiarism?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01986e",
   "metadata": {},
   "source": [
    "Tokenize the document.\n",
    "Remove all the stop words using NLTK library.\n",
    "Use GenSim library and find the most relevant words, line by line. This can be done by creating the LDA or LSA of the document.\n",
    "Use Google Search API to search for those words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ef9cb-c113-4140-9f7e-6e51546a4ae8",
   "metadata": {},
   "source": [
    "## 24. How will you define the number of clusters in a clustering algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ecf12a",
   "metadata": {},
   "source": [
    "The optimal number of clusters can be defined as follow: Compute clustering algorithm (e.g., k-means clustering) \n",
    "for different values of k. For each k, calculate the total within-cluster sum of square (wss). \n",
    "Plot the curve of wss according to the number of clusters k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98935311-a6a0-4672-a802-bd71236dc0af",
   "metadata": {},
   "source": [
    "## 25. Is it possible to perform logistic regression with Microsoft Excel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d7569",
   "metadata": {},
   "source": [
    "To activate the Logistic regression dialog box, start XLSTAT then select the XLSTAT / Modeling data / Logistic regression function. \n",
    "When you click on the button, the Logistic regression dialog box appears. Select the data on the Excel sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb9f9d-3c9b-44d6-aaac-d103a70540d0",
   "metadata": {},
   "source": [
    "## 26. What are Eigenvalue and Eigenvector?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede6997",
   "metadata": {},
   "source": [
    "Eigenvectors are unit vectors which mean that their length or magnitude is equal to 1. \n",
    "They are often referred to as right vectors which simply mean a column vector whereas eigenvalues \n",
    "are coefficients applied to eigenvector give the vectors their length or magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4efa4-f7f4-4095-ae3a-bad1a4316626",
   "metadata": {},
   "source": [
    "## 27. Compare SAS, R, And Python Programming?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c8d31",
   "metadata": {},
   "source": [
    "All big IT organizations choose SAS as their data analytics tools. As R is very good with heavy calculations, \n",
    "it is largely used by statisticians and researchers. Startups prefer Python over the other two due to its lightweight nature,\n",
    "large community, and deep learning capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabecb4-581e-44d8-bc60-16f5257ab37c",
   "metadata": {},
   "source": [
    "## 28. How regularly must an algorithm be updated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e9cf3",
   "metadata": {},
   "source": [
    "Algorithm can be updated regularly based on its need, usage, and market growth. For example, \n",
    "Google is reported to change its search algorithm around 500 to 600 times each year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdfe14-58c4-4057-901d-fe2b8a8f9aef",
   "metadata": {},
   "source": [
    "## 29. What is the goal of A/B Testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d85182",
   "metadata": {},
   "source": [
    "The goal of A/B testing is to find the best performing content for a specific goal (or goals). \n",
    "Choosing the goal of your test should be part of your test development process. \n",
    "Most marketers focus on improving one of a few different key performance indicators (KPIs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2cc4c-9e98-49e4-8155-473ffe54e509",
   "metadata": {},
   "source": [
    "# Cognizant Interview Questions For Freshers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1fcc0-398d-441f-b9fa-3805897ec91b",
   "metadata": {},
   "source": [
    "## 1. Explain what regularization is and why it is useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd5bf3",
   "metadata": {},
   "source": [
    "Regularization is a technique used for tuning the function by adding an additional penalty term in the error function. \n",
    "The additional term controls the excessively fluctuating function such that the coefficients don’t take extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198cb6d-0d07-4c23-986b-76c2dc64f437",
   "metadata": {},
   "source": [
    "## 2. Which data scientists do you admire most? which startups?z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22223749",
   "metadata": {},
   "source": [
    "Dean Abbott admire the most who is the Co-founder and chief data scientist, SmarterHQ because he is masterful at blendng data science with\n",
    "a deep understanding of data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ead130-3ca5-468e-9372-8f7f10cbf882",
   "metadata": {},
   "source": [
    "## 3. How would you validate a model you created to generate a predictive model of a quantitative outcome variable using multiple regression?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b3cc5-76d8-4567-9960-6de1ebb04245",
   "metadata": {},
   "source": [
    "The validation of a predictive model requires (i) divide the initial sample set into a training and validation datasets, \n",
    "(ii) infer a model with the training dataset, \n",
    "(iii) evaluate the quality of the model with the validation dataset by computing the aforementioned metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea24bd89-c3bc-4487-811e-4694bd77e788",
   "metadata": {},
   "source": [
    "## 4. Explain what precision and recall are. How do they relate to the ROC curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5af33a",
   "metadata": {},
   "source": [
    "## Recall\n",
    "\n",
    "Recall is the number of relevant documents retrieved by a search divided by the total number of existing relevant documents.\n",
    "\n",
    "## Precision\n",
    "\n",
    "Precision is the number of relevant documents retrieved by a search divided by the total number of documents retrieved by that search.\n",
    "\n",
    "ROC curve represents a relation between sensitivity (RECALL) and specificity(NOT PRECISION) is commonly used \n",
    "to measure the performance of binary classifiers. However, when dealing with highly skewed datasets, \n",
    "precision recall curves give a more representative picture of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6f8a8-9404-419f-811c-c26735e5d051",
   "metadata": {},
   "source": [
    "## 5. How can you prove that one improvement you’ve brought to an algorithm is really an improvement over not doing anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40887c4",
   "metadata": {},
   "source": [
    "There are several ideas with potential for improvement to yield better results for the task of improving an algorithm. \n",
    "It can be achieved using A/B testing, where both the versions of algorithm are kept running on similar environment \n",
    "for a considerably long time and real-life input data is randomly split between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc40c86-3ca2-44ba-bc5a-b3705876146a",
   "metadata": {},
   "source": [
    "## 6. What is root cause analysis?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde76f37",
   "metadata": {},
   "source": [
    "Root cause analysis (RCA) is the process of discovering the root causes of problems in order to identify appropriate solutions. \n",
    "It assumes that it is much more effective to systematically prevent and solve for underlying issues rather \n",
    "than just treating ad hoc symptoms and putting out fires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294fe974-7d25-4a2e-84f6-3fa02c692586",
   "metadata": {},
   "source": [
    "## 7. Are you familiar with price optimization, price elasticity, inventory management, competitive intelligence? Give examples.e gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5467fe22",
   "metadata": {},
   "source": [
    "### Price optimization: The best pricing optimization software utilizes artificial intelligence to measure price elasticity \n",
    "and predict the outcomes of various pricing strategies to generate revenue- or profit-maximizing prices.\n",
    "\n",
    "### Price elasticity: Price elasticity of demand is a measure used in economics to show the responsiveness,\n",
    "or elasticity, of the quantity demanded of a good or service to a change in its price when nothing but the price changes.\n",
    "\n",
    "### Inventory management: Inventory is the accounting of items, component parts and raw materials a company uses in production, or sells. \n",
    "Inventory management is to ensure that you have enough stock on-hand and to identify when there’s a shortage.\n",
    "\n",
    "### Competitive intelligence: Competitive intelligence helps to gather and analyze information about its industry, business environment, \n",
    "competitors, and competitive products and services. The gathering of the information and the analysis will support a \n",
    "company’s strategy as well as identify competitive gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65db2e3-be7f-4e3b-b664-d7251fde354c",
   "metadata": {},
   "source": [
    "## 8. What is statistical power?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b0c29",
   "metadata": {},
   "source": [
    "Statistical power is the probability that a test will correctly reject a false null hypothesis. \n",
    "Statistical power has relevance only when the null is false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cd54d-b134-4f5e-949c-803819a875c3",
   "metadata": {},
   "source": [
    "## 9. Explain what resampling methods are and why they are useful. Also explain their limitations?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca720de1",
   "metadata": {},
   "source": [
    "Resampling techniques are a set of methods to either repeat sampling from a given sample or population, or a way to estimate the precision of a statistic.\n",
    "For example, if you’re conducting a Sequential Probability Ratio Test and don’t come to a conclusion, then you resample and rerun the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b54b8fe-420c-4ec9-a0b1-0bf2951a1042",
   "metadata": {},
   "source": [
    "## 10. What is selection bias, why is it important and how can you avoid it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b5a52",
   "metadata": {},
   "source": [
    "Selection bias is the term used to describe the situation where an analysis has been conducted among a subset of the data (a sample)\n",
    "with the goal of drawing conclusions about the population, but the resulting conclusions will likely be wrong (biased), \n",
    "because the subgroup differs from the population in some important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392904fa-3b33-448f-88f7-b2b2f98b3575",
   "metadata": {},
   "source": [
    "## 11. Are expected value and mean value different?an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450b65c",
   "metadata": {},
   "source": [
    "Expected value is the average value of a random variable over a large number of experiments. \n",
    "A random variable maps numeric values to each possible outcome in an experiment.\n",
    "The Mean value of a dataset is the average value i.e. a number around which a whole data is spread out. \n",
    "All values used in calculating the average are weighted equally when defining the Mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c663e-aadf-407c-857a-6cde6848615f",
   "metadata": {},
   "source": [
    "## 12. What Is Power Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc7ebc",
   "metadata": {},
   "source": [
    "Power Analysis is the process of estimating one of the 4 variables given values for the 3 variables.\n",
    "It is commonly used to estimate the minimum sample size to carry out an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a13f6-0eda-49d7-84a0-5ad986d72413",
   "metadata": {},
   "source": [
    "## 13. How can you iterate over a list and also retrieve element indices at the same time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cefa0a4",
   "metadata": {},
   "source": [
    "There is an optional start argument to the enumerate function, which I find very helpful when \n",
    "I need to count from 1 or any other number instead of 0. for index, value in enumerate(numbers, start=1): \n",
    "Print ‘The value at position’, index, ‘is’, value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1a857-6e96-4eaa-86ca-6a104c06ffe5",
   "metadata": {},
   "source": [
    "## 14. Can you write the formula to calculate R-square?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ded8e",
   "metadata": {},
   "source": [
    "Calculate predicted values, subtract actual values and square the results. Then divide the first sum of errors (explained variance) \n",
    "by the second sum (total variance), subtract the result from one, and you have the R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b19018-f5a2-47ec-86bc-ecdb6858b567",
   "metadata": {},
   "source": [
    "## 15. What does NLP stand for?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c879a9",
   "metadata": {},
   "source": [
    "Natural language processing (NLP) is the ability of a computer program to understand human language as it is spoken \n",
    "and written referred to as natural language. It is a component of artificial intelligence (AI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d35a57-c9e7-4b76-a519-99f6d1f5f56b",
   "metadata": {},
   "source": [
    "## 16. What do you mean by word Data Science?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22080a",
   "metadata": {},
   "source": [
    "Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from \n",
    "structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a7f2e-b2f9-4af7-8081-49ef5446ea6b",
   "metadata": {},
   "source": [
    "## 17. Explain the term botnet?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fef41",
   "metadata": {},
   "source": [
    "A botnet is a collection of internet-connected devices infected by malware that allow hackers to control them. \n",
    "Cyber criminals use botnets to instigate botnet attacks, which include malicious activities such as credentials leaks, \n",
    "unauthorized access, data theft and DDoS attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb77de9-3c21-4ec2-86e4-215d1377f81b",
   "metadata": {},
   "source": [
    "## 18. What is Data Visualization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09f633",
   "metadata": {},
   "source": [
    "Data visualization, or ‘data viz’ as it’s commonly known, is the graphic presentation of data.\n",
    "Visualizations are aesthetically beautiful, providing layers of detail that generate deeper dimensions of insight and whole new layers of understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78696ed-b135-425d-9da0-4a780e125cfb",
   "metadata": {},
   "source": [
    "## 19. Why data cleaning plays a vital role in analysis?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d13f5",
   "metadata": {},
   "source": [
    "Data cleaning can help in analysis because: Cleaning data from multiple sources helps to transform it into a format that data analysts or \n",
    "data scientists can work with. Data Cleaning helps to increase the accuracy of the model in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c8c80-a68d-424a-8037-9155673e102d",
   "metadata": {},
   "source": [
    "## 20. What is Linear Regression?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c43fa",
   "metadata": {},
   "source": [
    "In statistics, linear regression is a linear approach to modelling the relationship between a dependent variable and \n",
    "one or more independent variables. In the case of one independent variable it is called simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f94515-28f7-48b6-b3f7-a43a7aa223fa",
   "metadata": {},
   "source": [
    "## 21. What do you understand by term hash table collisions?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199ccdd",
   "metadata": {},
   "source": [
    "The situation where a newly inserted key maps to an already occupied slot in the hash table is called collision and \n",
    "must be handled using some collision handling technique. Collisions are very likely even if we have big table to store keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ccc3a-4a7f-4251-a1c0-f1e64715c77e",
   "metadata": {},
   "source": [
    "## 22. Compare and contrast R and SAS?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3799b40",
   "metadata": {},
   "source": [
    "SAS is a specific programming language designed primarily for statistical analysis of data from spreadsheets or databases. \n",
    "R programming language is widely used among statisticians and data miners to develop statistical software and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b633d33e-0280-4b11-8c71-ad6271c50e9a",
   "metadata": {},
   "source": [
    "## 23. What do you understand by letter ‘R’?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2763b7c",
   "metadata": {},
   "source": [
    "R analytics (or R programming language) is free, open-source software used for all kinds of data science, statistics,\n",
    "and visualization projects. R allows building and running statistical models using Sisense data, \n",
    "automatically updating this as new information flows into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1746571-fccc-4db3-9398-644475770e89",
   "metadata": {},
   "source": [
    "## 24. What is the goal of A/B Testing?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d998b4c3",
   "metadata": {},
   "source": [
    "The ultimate goal of an A/B test is to build on the learnings from previous experiments and use those insights improve the pages being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adbafff-6104-43fd-9aae-1918f3384859",
   "metadata": {},
   "source": [
    "## 25. What are Eigenvalue and Eigenvector?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d2ad7",
   "metadata": {},
   "source": [
    "Eigenvectors are the vectors which when multiplied by a matrix (linear combination or transformation) results in another \n",
    "vector having same direction but scaled in forward or reverse direction by a magnitude of the scaler multiple which can be termed as Eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671e585-df7c-4bb2-9b7b-205e680653d6",
   "metadata": {},
   "source": [
    "## 26. What are the important libraries of Python that are used in Data Science?orch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db0f1d",
   "metadata": {},
   "source": [
    "NumPy.\n",
    "SciPy.\n",
    "Pandas, Keras.\n",
    "SciKit-Learn.\n",
    "PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488aa86-dfbc-49a6-a4bd-2bc769bd75b6",
   "metadata": {},
   "source": [
    "## 27. What is the Law of Large Numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a1392",
   "metadata": {},
   "source": [
    "The Law of Large Numbers is a theorem within probability theory that suggests that as a trial is repeated, and more data is gathered, \n",
    "the average of the results will get closer to the expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43bc83-039a-4b0f-b3b6-70e2bb220f93",
   "metadata": {},
   "source": [
    "## 28. How Machine Learning Is Deployed In Real World Scenarios?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf37825",
   "metadata": {},
   "source": [
    "Machine learning model can be deployed by writing RestAPI’s around it. The few real world examples are Image recognition,\n",
    "speech recognition, medical diagnosis statistical arbitrage, and predictive analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f68868-db16-4a08-921a-d1000668f403",
   "metadata": {},
   "source": [
    "## 29. Why data cleaning plays a vital role in the analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706deac",
   "metadata": {},
   "source": [
    "Data cleaning can help in analysis because: Cleaning data from multiple sources helps to transform it into a format that data analysts or \n",
    "data scientists can work with. Data Cleaning helps to increase the accuracy of the model in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c4510-f25f-4002-a170-cd578257c69a",
   "metadata": {},
   "source": [
    "# Tech Mahindra Interview Questions For Freshers in Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6e211b-e818-4c85-9a48-c3bdc38c1771",
   "metadata": {},
   "source": [
    " ## 1.What is Jenkins pipeline? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66e6b3",
   "metadata": {},
   "source": [
    "Ans:--. Jenkins Pipeline: An automated process for building, testing, and deploying code, defined as code using the Groovy-based DSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e767c8e-a003-4d5f-945d-ceb23e756b72",
   "metadata": {},
   "source": [
    "## 2. How do you use Jenkins to automate CI/CD?e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b2a1a",
   "metadata": {},
   "source": [
    "Ans:--. By setting up Jenkins pipelines to automate the build, test, and deployment processes, integrating with version control, and configuring \n",
    "various stages of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745543f-30f0-4ae8-9407-e44c92754406",
   "metadata": {},
   "source": [
    "## 3.When will a model be redeployed?oyment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81472c3",
   "metadata": {},
   "source": [
    "Ans:--. A model will be redeployed when:\n",
    "\n",
    "The model is retrained with new data.\n",
    "Improvements or updates are made to the model.\n",
    "There are changes in the production environment or dependencies.\n",
    "Performance issues or bugs are detected in the current deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354d6de-76fb-421b-9ecb-cb20b7f64741",
   "metadata": {},
   "source": [
    "## 4.What is Linear Regression?ion?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948ca92",
   "metadata": {},
   "source": [
    "Ans:--.  Linear Regression is a supervised learning algorithm used for predicting a continuous dependent variable based on one or more independent \n",
    "    variables by fitting a linear relationship between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12291f-10c4-448b-84c5-79bae6ae0374",
   "metadata": {},
   "source": [
    "## 5. What is Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c894584",
   "metadata": {},
   "source": [
    "A:--.Logistic Regression is a supervised learning algorithm used for binary classification tasks. It predicts the probability of a binary \n",
    "outcome using a logistic function to model the relationship between the dependent variable and one or more independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf709791-5901-4ce0-b88c-2c46892f0ca6",
   "metadata": {},
   "source": [
    "## 6.What is a Decision Tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9df707",
   "metadata": {},
   "source": [
    "A:--. Decision Tree is a supervised learning algorithm used for both classification and regression tasks. It splits the data into subsets \n",
    "based on the value of input features, creating a tree-like model of decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ea9ec-7d04-4ac4-bad3-6fcdd4ca59ed",
   "metadata": {},
   "source": [
    "## 7.What is a Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f720a9b3",
   "metadata": {},
   "source": [
    "A:--. Random Forest is an ensemble learning method that combines multiple decision trees to improve the model’s accuracy and prevent overfitting. \n",
    "It creates a ‘forest’ of random decision trees and aggregates their predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9f745-bda6-4aa7-abb5-41f8032d1da4",
   "metadata": {},
   "source": [
    "## 8.What is Naive Bayes Theory?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715b750",
   "metadata": {},
   "source": [
    "A:--. Naive Bayes is a probabilistic classification algorithm based on Bayes’ Theorem. It assumes independence between the features and calculates the \n",
    "probability of each class based on the input features, selecting the class with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa375b6-2220-4a44-9567-ecc291566acf",
   "metadata": {},
   "source": [
    "## 9.How do you handle null values in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba307d",
   "metadata": {},
   "source": [
    " ### Handling null values can be done in several ways:\n",
    "\n",
    "#### Removal: \n",
    "Remove rows or columns with null values.\n",
    "#### Imputation: \n",
    "Fill null values with a specific value like the mean, median, mode, or a fixed value.\n",
    "#### Prediction: \n",
    "Use predictive models to estimate and replace null values.\n",
    "#### Flagging: \n",
    "Create a separate binary feature indicating the presence of null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82166f-1aab-4d60-8ee2-1858fb9c2313",
   "metadata": {},
   "source": [
    "## 10.What are your favorite libraries in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742af79c",
   "metadata": {},
   "source": [
    "One of my favorite libraries in Python is Pandas. It’s great for data manipulation and analysis. With Pandas, you can easily read data from different \n",
    "file formats, clean it, and perform various operations to get insights quickly. Another favorite is NumPy, which is essential for numerical computations \n",
    "and handling arrays efficiently. Lastly, I really like Matplotlib for creating visualizations; it makes it easy to generate plots and \n",
    "charts to understand data better. For example, I often use Pandas to clean my datasets, NumPy to perform calculations, \n",
    "and Matplotlib to visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354fa0e-aa8b-49a0-b695-78e3adb135bf",
   "metadata": {},
   "source": [
    "## 11.What is the difference between Logistic and Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e80b7",
   "metadata": {},
   "source": [
    "## Linear Regression:\n",
    "\n",
    "#### Purpose: \n",
    "Predicts a continuous outcome based on input variables.\n",
    "#### Output: \n",
    "Gives a straight-line prediction (like predicting house prices).\n",
    "#### Equation:\n",
    "Uses a simple linear equation to find a relationship between variables.\n",
    "#### Use: \n",
    "Best for tasks where the result is a number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a84326",
   "metadata": {},
   "source": [
    "## Logistic Regression:\n",
    "\n",
    "#### Purpose:\n",
    "Predicts the probability of a categorical outcome.\n",
    "#### Output: \n",
    "Provides probabilities that map to binary outcomes (like yes/no or spam/not spam).\n",
    "#### Equation:\n",
    "Uses a logistic function to model the probability.\n",
    "#### Use: \n",
    "Ideal for tasks where the result is a category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab0fbf",
   "metadata": {},
   "source": [
    "## Key Differences:\n",
    "\n",
    "#### Output Type:\n",
    "Linear regression predicts numbers; logistic regression predicts probabilities.\n",
    "#### Application:\n",
    "Linear regression for numbers, logistic regression for categories.\n",
    "\n",
    "In essence, linear regression predicts numbers (like house prices), while logistic regression predicts probabilities and maps \n",
    "them to categories (like yes/no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac304a-1b5b-4779-86de-0fe3aa11b14f",
   "metadata": {},
   "source": [
    "## 12.What is the difference between data science and big data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819d4dc-f486-44cd-a9c9-56358f7daa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Science:\n",
    "\n",
    "Focus: Using data to solve problems and make decisions.\n",
    "Tasks: Analyzing, visualizing, and modeling data to find insights.\n",
    "Tools: Statistics, machine learning, Python/R programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7cabf7-b5e7-40c4-9d02-40721a6826c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Big Data:\n",
    "\n",
    "Focus: Dealing with large and complex datasets.\n",
    "Characteristics: High volume, speed, and variety of data.\n",
    "Challenges: Storing, managing, and analyzing massive amounts of data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4261615-fdd5-4ca9-bf7f-347d21bbf0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Key Differences:\n",
    "\n",
    "Focus: Data science analyzes data; big data handles large datasets.\n",
    "Tools: Data science uses stats and ML; big data uses special tech for storage and processing.\n",
    "In essence, data science applies tools to analyze data for insights, while big data deals with storing and managing large, varied datasets efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d707c7bd-d69c-400d-a5c7-0a0c7af3484d",
   "metadata": {},
   "source": [
    "## What is Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8fa8c-21b0-438f-bb49-0f41710b84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Word2Vec is a technique in natural language processing (NLP) used to convert words into vectors of numerical values. \n",
    "It captures semantic relationships between words based on their contexts in large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee5a77-423c-487f-823d-a92cedf468bb",
   "metadata": {},
   "source": [
    "## What is TF-IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0674ee2-5648-4751-8baf-c46d6fccf421",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used to evaluate the importance of a word in a document \n",
    "relative to a collection of documents. It reflects how frequently a term appears in a document adjusted by how often it appears across all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add02336-f3ff-4b4c-8289-a4ec960dfbf9",
   "metadata": {},
   "source": [
    "# Ibm Data Science recent interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d254a-bcac-4ee0-b175-dbf22d317541",
   "metadata": {},
   "source": [
    "## 1. What do you mean by word Data Science?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6ecd9-4b5a-4b59-8034-c8e2b4f99944",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data science is the field of study that combines domain expertise, programming skills, and knowledge of mathematics and statistics \n",
    "to extract meaningful insights from data. It encompasses preparing data for analysis, including cleansing, aggregating, and manipulating \n",
    "the data to perform advanced data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b6940-d094-4ae7-a8ac-50eb93bfe83a",
   "metadata": {},
   "source": [
    "## 2. Explain the term botnet?\n",
    "on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa181f-5630-4821-966d-0a0c58e0d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "A botnet is a collection of internet-connected devices infected by malware that allow hackers to control them. Cyber criminals use botnets to \n",
    "instigate botnet attacks, which include malicious activities such as credentials leaks, unauthorized access, data theft and DDoS attacks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491668fb-3bfd-49f9-b0ab-dc99c07934ca",
   "metadata": {},
   "source": [
    "## 3. What is Data Visualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6063d-c234-46dc-8460-edc5fe00b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data visualization is the graphical representation of information and data. By using visual elements like charts, graphs, and maps, \n",
    "data visualization tools provide an accessible way to see and understand trends, outliers, and patterns in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac6f1b-9332-41c3-b98f-13e26386193c",
   "metadata": {},
   "source": [
    "## 4. How you can define Data cleaning as a critical part of process?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb48dd-dcb3-4bf4-b4a2-277f03ee3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data cleaning is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. \n",
    "If data is incorrect, outcomes and algorithms are unreliable, even though they may look correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bff61-a21a-4716-98d8-5ebe394b5241",
   "metadata": {},
   "source": [
    "## Differentiate between Data modelling and Database design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0cb66e-b804-4c41-a68c-ca2d68908623",
   "metadata": {},
   "outputs": [],
   "source": [
    "Database design is stored in the database schema, which is in turn stored in the data dictionary. \n",
    "Data model is a set or collection of construct used for creating a database and producing designs for the databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29f6c9-76b9-4436-a1f8-ae6c41cb045e",
   "metadata": {},
   "source": [
    "## What are Recommender Systems?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8b28d-c760-4108-af4e-00686ca76c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "A Recommender System refers to a system that is capable of predicting the future preference of a set of items for a user, and recommend the top items. \n",
    "One key reason why we need a recommender system in modern society is that people have too much option to use from due to the prevalence of Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d4ada-8cd4-4d51-b5e1-892277017179",
   "metadata": {},
   "source": [
    "## Why data cleaning plays a vital role in analysis?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507846b-33b5-4a1f-a820-a3b102e51c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data cleaning can help in analysis because: Cleaning data from multiple sources helps to transform it into a format that data analysts or \n",
    "data scientists can work with. Data Cleaning helps to increase the accuracy of the model in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc85ee3-9a0b-4d30-91f1-600c494e9561",
   "metadata": {},
   "source": [
    "## What is Linear Regression?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd73654-61c6-4ce3-a46f-7cb1698a8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear Regression is a very powerful statistical technique and can be used to generate insights on consumer behavior, understanding business and \n",
    "factors influencing profitability. Linear regressions can be used in business to evaluate trends and make estimates or forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddb5e6-e1a6-4289-be0f-3fa787d802a9",
   "metadata": {},
   "source": [
    "## What do you understand by term hash table collisions?t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0b349-83b9-4053-9ac2-3da6cb605e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A collision occurs when two keys are hashed to the same index in a hash table. Collisions are a problem because every slot in a hash table is \n",
    "supposed to store a single element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b69e1-559b-4e42-a9ea-d0639905c741",
   "metadata": {},
   "source": [
    "## What are various steps involved in an analytics project?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314e56d-8909-4d95-baad-a32b79e098ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "The data analytics encompasses six phases that are data discovery, data aggregation, planning of the data models, data model execution, \n",
    "communication of the results, and operationalization. These six phases of data analytics lifecycle are iterative \n",
    "with backward and forward and sometimes overlapping movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587e6c9-d307-4144-a5b6-77f32a778cd1",
   "metadata": {},
   "source": [
    "## How can you iterate over a list and also retrieve element indices at the same time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd3cc0-3119-44be-8cfd-6d5111243774",
   "metadata": {},
   "source": [
    "A optional start argument is used to enumerate the function which is very helpful when I need to count from 1 or any other number instead of 0. \n",
    "for index, value in enumerate(numbers, start=1): print ‘The value at position’, index, ‘is’, value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd18f9-0088-422d-a058-532c9a9bc888",
   "metadata": {},
   "source": [
    "## What is collaborative filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d28c4f-8c74-4a25-ac05-030e0621397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Collaborative filtering is a class of recommenders that leverage only the past user-item interactions in the form of a ratings matrix. \n",
    "It is a technique used by recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459120d-8f0a-4a9d-9ef7-90f72252a517",
   "metadata": {},
   "source": [
    "## What is boosting?ults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3b92c-99ed-48dd-9347-21d354d19ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boosting is an ensemble learning technique that uses a set of Machine Learning algorithms to convert weak learner to strong learners \n",
    "in order to increase the accuracy of the model.\n",
    "\n",
    "## For tuning hyperparameters of your machine learning model, what will be the ideal seed?\n",
    "Grid search is arguably the most basic hyperparameter tuning method. With this technique, we simply build a model for each possible combination \n",
    "of all of the hyperparameter values provided, evaluating each model, and selecting the architecture which produces the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac3f49-8109-442a-ada1-a042db519083",
   "metadata": {},
   "source": [
    "##  Compare and contrast R and SAS?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37044269-48e4-443e-b479-bc5a5e171368",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAS is a specific programming language designed primarily for statistical analysis of data from spreadsheets or databases. \n",
    "R programming language is open source free software widely used among statisticians and data miners to develop statistical software and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607721af-95dd-4861-9af9-6a678bb3106a",
   "metadata": {},
   "source": [
    "## What do you understand by letter ‘R’?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517e120-2fd3-4916-acfc-2e2da751fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "R analytics (or R programming language) is free, open-source software used for all kinds of data science, statistics, \n",
    "and visualization projects. R also allows you to build and run statistical models using Sisense data, automatically \n",
    "updating this as new information flows into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e096d8-ffa0-4de2-96a8-302c8ffb7a50",
   "metadata": {},
   "source": [
    "## What is Interpolation and Extrapolation?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b3b99-b115-4174-89ea-1fbc1972d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extrapolation is an estimation of a value based on extending a known sequence of values or facts beyond the area that is certainly known. \n",
    "Interpolation is an estimation of a value within two known values in a sequence of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ecb45-aac5-45d0-a2a6-33536da4b788",
   "metadata": {},
   "source": [
    "## What is the difference between Cluster and Systematic Sampling?r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d4b12-055c-42b8-a6fa-2664fd930eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Systematic sampling selects a random starting point from the population, and then a sample is taken from regular fixed intervals of the population \n",
    "depending on its size. Cluster sampling divides the population into clusters and then takes a simple random sample from each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169ba3a-717d-4ba5-b612-7941d76e758a",
   "metadata": {},
   "source": [
    "##  Are expected value and mean value different?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51090f-37b0-4885-9ca1-e5c282c4b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "Expected value is the average value of a random variable over a large number of experiments. A random variable maps numeric values to each \n",
    "possible outcome in an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83962a92-1093-4ba5-aeec-58137fddb7c7",
   "metadata": {},
   "source": [
    "## What does P-value signify about the statistical data?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bfb27b-195a-4f20-8410-044359b3213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The P value is defined as the probability under the assumption of no effect or no difference (null hypothesis), of obtaining a result \n",
    "equal to or more extreme than what was actually observed. The P stands for probability and measures how likely it is that any observed \n",
    "difference between groups is due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4eebb4-d25a-4c17-8f56-835c05b051b4",
   "metadata": {},
   "source": [
    "## What is the goal of A/B Testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2985bf6-e048-445b-947c-649d0a324488",
   "metadata": {},
   "outputs": [],
   "source": [
    "A/B testing is a basic randomized control experiment. It is a way to compare the two versions of a variable to find out which performs better in \n",
    "a controlled environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0eb88f-2c11-4376-9c2d-b657e8ca72db",
   "metadata": {},
   "source": [
    "## What is an Eigenvalue and Eigenvector?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a2460-b1d0-4520-a2ed-fba3f6dbf9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eigenvectors are unit vector that their length or magnitude is equal to 1. They are often referred to as right vectors which simply mean \n",
    "a column vector whereas, eigenvalues are coefficients applied to eigenvectors that give the vectors their length or magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630d1de-ac99-4e52-bb0a-141903fa69b6",
   "metadata": {},
   "source": [
    "## How can you assess a good logistic model?l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9a024-8e84-4dda-a7e2-a414be30aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotting the pairs of sensitivity and specificities (or, more often, sensitivity versus one minus specificity) on a scatter plot provides \n",
    "an ROC (Receiver Operating Characteristic) curve. The area under this curve (AUC of the ROC) provides an overall measure of fit of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facad21a-2a66-473f-8bc6-da0f205e7097",
   "metadata": {},
   "source": [
    "## What is Machine Learning?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3de25-af49-4623-9825-0071c0a5b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine learning is a division of computer science which contracts with system programming in order to mechanically learn and perk up with experience. \n",
    "For example, Robots are programmed so that they can carry out the task based on data they collect from sensors. \n",
    "It mechanically learns programs from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9063b-68f3-48e3-8ad1-c64992477695",
   "metadata": {},
   "source": [
    "## Why do you want to work as a data scientist?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203484f-36bd-47af-84e0-d46d8664898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data scientist work with passion towards working for data-driven by solving issues using an analytical approach and passionate about \n",
    "incorporating technology into the work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb394c2-beb4-435f-bbdb-11703fd3d037",
   "metadata": {},
   "source": [
    "## What is the Law of Large Numbers?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3335ddb-ea3f-4e1b-bb0b-37e38442243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "The law of large numbers states that an observed sample average from a large sample will be close to the true population average and that \n",
    "it will get closer the larger the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dce22c-e110-4607-a134-91dada81d595",
   "metadata": {},
   "source": [
    "## Why is data cleaning essential in Data Science?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03121a93-a102-4fed-b92e-7dc67330e235",
   "metadata": {},
   "source": [
    "Clean data increase the overall productivity and allow for the highest quality information in your decision-making. \n",
    "The benefit includes removal of errors when multiple sources of data are at play. Fewer errors make for happier clients and less-frustrated employees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e518ba-3bb3-412f-a8d3-0e779f030b82",
   "metadata": {},
   "source": [
    "##  What Is K-means? How Can You Select K For K-means?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cd677-ccc4-4132-becf-c11e4413c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "K-means clustering is a method of vector quantization that aims to partition n observations into k clusters in which each observation belongs \n",
    "to the cluster with the nearest mean serving as a prototype of the cluster. There is a popular method known as elbow method \n",
    "which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be18549-3a59-45b7-80fa-0b11d277ec70",
   "metadata": {},
   "source": [
    "## What is underfitting?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb908dd2-849a-45c6-888b-fd2447a8f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Underfitting refers to a model that can neither model the training data nor generalize to new data. An underfit machine \n",
    "learning model is not a suitable model and will be obvious as it will have poor performance on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d402324-7c6d-4c0d-b60a-648b028b8fae",
   "metadata": {},
   "source": [
    "# Hexaware Technologies interview questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e78d62-946c-43a2-ba6e-fe845993e9f9",
   "metadata": {},
   "source": [
    "## What is classifier in machine learning?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1db06-c8ec-44be-b75f-c5cb86254774",
   "metadata": {},
   "outputs": [],
   "source": [
    "A classifier in machine learning is an algorithm that automatically orders or categorizes data into one or more of a set of “classes.” \n",
    "One of the most common examples is an email classifier that scans emails to filter them by class label: Spam or Not Spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f29b1-39a6-4c22-9e25-879d0b77b6eb",
   "metadata": {},
   "source": [
    "## What are the advantages of Naive Bayes?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be6628-cbac-4745-8c49-9cf82be696b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "It handles both continuous and discrete data. It is highly scalable with the number of predictors and data points. \n",
    "It is fast and can be used to make real-time predictions. It is not sensitive to the irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f3a58-3301-4bb6-83e8-cc27b1a2c5d2",
   "metadata": {},
   "source": [
    "## In what areas Pattern Recognition is used?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab822ee4-ccf4-41a1-83ec-3ce9a54abd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pattern recognition is the automated recognition of patterns and regularities in the data. It has applications in statistical data analysis, \n",
    "signal processing, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc99e5-239b-48cb-8a1a-a152bab22133",
   "metadata": {},
   "source": [
    "## What is Genetic Programming?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96dd83-93f4-4089-b49f-859d515199c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Genetic programming is a domain-independent method that genetically breeds a population of computer programs to solve a problem. Specifically,\n",
    "genetic programming iteratively transforms a population of computer programs into a new generation of programs by applying analogs of \n",
    "the naturally occurring genetic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085bc8c-2c53-4d62-8de6-51c8ffe7620e",
   "metadata": {},
   "source": [
    "## What is Inductive Logic Programming in Machine Learning?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172fff2-ebe7-4bdd-b177-ffc161936a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inductive logic programming is the subfield of machine learning that the uses first-order logic to represent hypotheses and data. Because \n",
    "first-order logic is expressive and declarative, inductive logic programming specifically targets problems involving \n",
    "structured data and background knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220f8e44-cd88-4a0e-8a8c-7589428ae8ba",
   "metadata": {},
   "source": [
    "## What is Model Selection in Machine Learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5df4b-0da4-4315-8d75-d06726d695dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model selection is the process of selecting one final machine learning model from among a collection of candidate machine learning models for \n",
    "a training dataset. Model selection is the process of choosing the one of the models as the final model that addresses the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a5a2b-89a0-483d-8382-9ab3ec0d83b7",
   "metadata": {},
   "source": [
    "##  What are the two methods used for the calibration in Supervised Learning?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974ea57-9fff-40c7-8524-498bc35bd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are two types of Supervised Learning techniques: Regression and Classification. Classification separates the data, Regression fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c69b0-f68f-4e3a-9904-10046c6b3a81",
   "metadata": {},
   "source": [
    "## Which method is frequently used to prevent overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0ec05-75e7-4dcd-923c-97af3bd7bdc0",
   "metadata": {},
   "source": [
    "Regularization methods are so widely used to reduce overfitting that the term “regularization” may be used for any method that the \n",
    "improves the generalization error of a neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a2362-f392-4614-88b7-5df0aa861d7e",
   "metadata": {},
   "source": [
    "## What is the difference between heuristic for rule learning and heuristics for decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c6009-4f4b-4369-bbb4-9afcae5c1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Heuristic for rule learning and heuristics for decision trees. The difference is that the heuristics for decision trees evaluate the \n",
    "average quality of a number of disjointed sets while rule learners only evaluate the quality of the set of instances that is \n",
    "covered with the candidate rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28952046-700d-4178-93c7-0623ce4b5d00",
   "metadata": {},
   "source": [
    "## What is Perceptron in Machine Learning?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a00c57-5989-4481-be19-417b1326d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "The perceptron is an algorithm for supervised learning of binary classifiers. It is a type of linear classifier, a classification algorithm \n",
    "that makes its predictions based on a linear predictor function combining a set of the weights with the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea8d3f-2c6b-4edc-b2fd-240872e3d0b9",
   "metadata": {},
   "source": [
    "## Explain the two components of Bayesian logic program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2a996-6451-4b46-b741-36f6077be2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "The first component is the logical one. It consists of a set of Bayesian clauses which captures the qualitative structure of the domain \n",
    "and is based on the”pure” Prolog. The second component is the quan- titative one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920c606-4e9e-48ae-9313-cad0f4bba949",
   "metadata": {},
   "source": [
    "##  What are Bayesian Networks (BN) ?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a11e5-b6fa-4438-92d9-f930b2325dfc",
   "metadata": {},
   "source": [
    "Bayesian networks are a type of Probabilistic Graphical Model that can be used to the build models from data or expert opinion. \n",
    "They can be used for a wide range of tasks including prediction, anomaly detection, diagnostics, automated insight, reasoning, \n",
    "time series prediction and decision making under uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82f65c-aafd-4683-a312-db69cb35b292",
   "metadata": {},
   "source": [
    "## Why instance based learning algorithm sometimes referred as Lazy learning algorithm?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59be8f-25d2-407d-b33c-1f050edf2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Instance-based methods are sometimes referred to as the lazy learning methods because they delay processing until a new instance \n",
    "must be classified. The nearest neighbors of an instance are defined in the terms of Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd167d2d-ea91-4813-b3f3-055a74af1a27",
   "metadata": {},
   "source": [
    "## What are the two classification methods that SVM ( Support Vector Machine) can handle?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae6352-cc03-4679-a999-6707a8934600",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear SVM is used for the linearly separable data, which means if a dataset can be classified into two classes by using a single straight line, \n",
    "then such data is termed as linearly separable data, and classifier is used called as Linear SVM classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d1f697-bb7e-44f3-8314-aff5fb1553dd",
   "metadata": {},
   "source": [
    "## What is ensemble learning?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a560e5-eef9-4029-a3f3-b4a1690850ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "An ensemble is a machine learning model that the combines the predictions from two or more models. The models that contribute to the ensemble, \n",
    "referred to as ensemble members, may be the same type or different types and may or may not be trained on the same training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e7bca-0d3e-4e3b-a0cf-d45725e31a26",
   "metadata": {},
   "source": [
    "## Why ensemble learning is used?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba493d4e-de5c-4462-83e8-b5370663f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble learning is the process by which the multiple models, such as classifiers or experts, are strategically generated and combined \n",
    "to solve a particular computational intelligence problem. Ensemble learning is primarily used to improve the classification, prediction, \n",
    "function approximation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c99ce-0427-403f-8fdd-7c94e6172fb1",
   "metadata": {},
   "source": [
    "# Amazon Data Science Interview Questions For Freshers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29d802-564a-40d4-825f-9f2463934590",
   "metadata": {},
   "source": [
    " ## Estimate the probability of a disease in a particular city given that the probability of the disease on a national level is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81c5ca-0cda-458b-a373-638de04ecb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes theorem helps to estimate the probability of a disease in a particular city in which the probability of the disease on a national level is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb19bb-6166-4c8a-ad61-550c64004b14",
   "metadata": {},
   "source": [
    "## How will inspect missing data and when are they important for your analysis?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8737c63-d147-499f-8f73-8d09f465fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The most common approach to the missing data is to simply omit those cases with the missing data and analyze the remaining data. \n",
    "This approach is known as the complete case (or available case) analysis or listwise deletion. The concept of missing values \n",
    "is important to understand in order to successfully manage data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be86fba-1ebf-48e0-b7f4-a4286251eb1b",
   "metadata": {},
   "source": [
    "## How will you decide whether a customer will buy a product today or not given the income of the customer, location where the customer lives, profession and gender? Define a machine learning algorithm for this.rove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a1883-3546-421d-a541-444bb7fae748",
   "metadata": {},
   "outputs": [],
   "source": [
    "For any give situation, the following five core steps are needed to define a machine learning algorithm,\n",
    "Get Data. The first step in the Machine Learning process is getting data for the given situation.\n",
    "Clean, Prepare & Manipulate Data because real-world data often has unorganized, missing, or noisy elements.\n",
    "Train Model. This step is where the magic happens! To solve the problem.\n",
    "Test Model. Now, it’s time to validate the trained model for improvement and finally improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210aa49-3a37-4f22-94b7-712bb2658806",
   "metadata": {},
   "source": [
    "## From a long sorted list and a short 4 element sorted list, which algorithm will you use to search the long sorted list for 4 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0beb9c8-9d20-4b32-a5a8-1a99ec4857eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary search is an efficient algorithm for finding an item from a sorted list of items. It works by repeatedly dividing in half the portion \n",
    "of the list that could contain the item, until narrowed down the possible locations to just one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee8535-c561-446b-b716-cb35d9e297da",
   "metadata": {},
   "source": [
    "## Why do you want to work as a data scientist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae9af9-146f-4f80-83ad-6fe675fc4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Scientist is the hottest job that helps to brings in skill sets and knowledge from various backgrounds such as mathematics, statistics, \n",
    "Analytics, modeling, and business acumen. These skills help them to identify patterns which can help the organization \n",
    "to recognize new market opportunities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c3dae7-8523-401a-b2ff-f76209f29721",
   "metadata": {},
   "source": [
    "## What Is K-means? How Can You Select K For K-means?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c4aea-dc4f-4a2c-88f9-60933a6ce149",
   "metadata": {},
   "outputs": [],
   "source": [
    "K-means clustering is one of the simplest and popular unsupervised machine learning algorithms. There is a popular \n",
    "method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm.\n",
    "This method is used to plots the various values of cost with changing k. As the value of K increases, there will be fewer elements in the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a6bbf6-5628-4b7c-ba3a-dce56e7e45e6",
   "metadata": {},
   "source": [
    "## What are the differences between overfitting and underfitting?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5249c6-d4d1-4f50-b693-e2265592d76a",
   "metadata": {},
   "source": [
    "Overfitting is a modeling error which occurs when a function is too closely fit to a limited set of data points. \n",
    "Underfitting refers to a model that can neither model the training data nor generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a3963-ec1f-4126-bdb3-bafcc8343e62",
   "metadata": {},
   "source": [
    "## What is collaborative filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10238513-5743-4fb2-862f-1d02bca84139",
   "metadata": {},
   "outputs": [],
   "source": [
    "Collaborative filtering (CF) is a technique used by recommender systems which is a method of making automatic predictions about \n",
    "the interests of a user by collecting preferences or taste information from many users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1353ca50-c4f5-4cea-b861-7911adae2384",
   "metadata": {},
   "source": [
    "##  What are the types of biases that can occur during sampling?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3328ea8-cb1a-4485-88b0-ebf23076decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sampling bias occurs when some members of a population are systematically more likely to be selected in a sample than others. \n",
    "The some common types of sampling bias include self-selection, non-response, undercoverage, survivorship, pre-screening or advertising, \n",
    "and healthy user bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8caca7-f1b4-4ae5-ab6a-1c9bd073bf5a",
   "metadata": {},
   "source": [
    "## Explain Star Schema?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135d589-9a95-40be-8c50-90d8c59c0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Star schema is the fundamental, simplest schema among the data mart schema. It is widely used to develop or build a data warehouse\n",
    "and dimensional data marts. It includes one or more fact tables indexing any number of dimensional tables and the cause of the snowflake schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6baad6-1bd5-4ba7-bc7c-16de15b75bf0",
   "metadata": {},
   "source": [
    "## How can you compare a neural network that has one layer, one input and output to a logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f5460-af25-496e-be82-300e1c13d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "The difference between a classification and regression is that a classification outputs a prediction probability for class/classes and regression\n",
    "provides a value. We can make a neural network to output a value by simply changing the activation function in the final layer to output the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3d59a-dc2e-4106-957c-c3e6be47a2fe",
   "metadata": {},
   "source": [
    "## How do you treat colinearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f37186-b3e7-4cd2-8852-c284bf4311e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Colinearity is treated by remove some of the highly correlated independent variables. Linearly combine the independent variables, \n",
    "such as adding them together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7c294-b4c4-4472-a201-4915a6a9b43f",
   "metadata": {},
   "source": [
    "## How will you deal with unbalanced data where the ratio of negative and positive is huge?tios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12aed7-3599-4924-af96-a33027a4faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use the right evaluation metrics.\n",
    "Resample the training set.\n",
    "Use K-fold Cross-Validation in the right way.\n",
    "Ensemble different resampled datasets.\n",
    "Resample with different ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e7de8-9050-4504-8156-b1b1dd660af8",
   "metadata": {},
   "source": [
    "## What is the difference between\n",
    "### \n",
    "i) Stack and queue\n",
    "### \n",
    "\n",
    "ii) LinkedIn and arrg pointers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff829c-3c08-43d7-95fc-3cd6578ae109",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stack and Queue\n",
    "\n",
    "Stack is used in solving problems works on recursion.Queue is used in solving problems having sequential processing. \n",
    "The difference between stacks and queues is in removing. In a stack we remove the item the most recently added; \n",
    "in a queue, we remove the item the least recently added.\n",
    "\n",
    "Linkedin and Array\n",
    "\n",
    "Array is a collection of elements of similar data type whereas Linked List is an ordered collection of elements of same type, \n",
    "which are connected to each other using pointers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4a22c-9c33-4aa5-b9b3-d95bb873d8ec",
   "metadata": {},
   "source": [
    "## What are the types of machine learning?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977a40a-aba3-4b7a-8fff-0323a33c6dca",
   "metadata": {},
   "source": [
    "Machine learning (ML) is a type of artificial intelligence (AI) that allows software applications to become more accurate at predicting outcomes \n",
    "without being explicitly programmed to do so. The three types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37c7f6-ec31-4dd8-9a65-8336a6df2dfa",
   "metadata": {},
   "source": [
    "## What is meant by supervised and unsupervised learning in data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f7018-f053-42bd-95d6-8e418494576f",
   "metadata": {},
   "source": [
    "To put it simply, supervised learning uses labeled input and output data, while an unsupervised learning algorithm does not. \n",
    "In supervised learning, the algorithm “learns” from the training dataset by iteratively making predictions on the data and adjusting \n",
    "for the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2dc105-f30e-4d65-b19c-fe19b2c0582e",
   "metadata": {},
   "source": [
    "##  Compare Sas, R, And Python Programming?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fefcd-7cd9-49af-b4e5-d0f2029e0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAS is probably the easiest to learn of all three. It has a good GUI that makes it even easier to learn and use. Python is a high level, \n",
    "object-oriented language, and is easier to learn than R. When it comes to learning, SAS is the easiest to learn, followed by Python and R."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd645561-4cde-4be9-9693-49c8e435a786",
   "metadata": {},
   "source": [
    "##  What are the time series algorithms?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4c03d-c598-4d95-a03b-64c92472f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time-series data is simply a set of ordered data points with respect to time. The Time Series mining function provides the following algorithms \n",
    "to predict future trends: Autoregressive Integrated Moving Average (ARIMA) Exponential Smoothing, Seasonal Trend Decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217cb5dc-d210-4c04-8336-b09ac6104c35",
   "metadata": {},
   "source": [
    "## What is Interpolation and Extrapolation?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc22993-228b-4e44-b86f-c6e805c52da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "When we predict values that fall within the range of data points taken it is called interpolation. When we predict values for points outside \n",
    "the range of data taken it is called extrapolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b602f-2e71-4cc9-ba99-170dabe163a9",
   "metadata": {},
   "source": [
    "# MICROSOFT DATA SCIENCE INTERVIEW QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bad52c-b526-4392-8b79-ad2538383d60",
   "metadata": {},
   "source": [
    "## On a scale of 1–10, how comfortable are you with Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8edf7-fd18-4724-bcbd-7166624ddbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "The interviewer ask this question to know how much do you know that you don’t know, so make sure to back your score with explanation on what \n",
    "you need to score higher. You can even throw it back to them and ask how your company would make me reach an 8 or 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89d2fe-fa7a-4adb-9614-21ebb12e4a77",
   "metadata": {},
   "source": [
    "##  How do you write functions in Python?de."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d707a-d563-467c-b4e9-490ce77ebae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Begin the definition of a new function with def followed by the name of the function and follow the rules for variable names.\n",
    "Then parameters in parentheses, colon.\n",
    "Then an indented block of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daab067-0c20-4824-a542-d6566b7f5118",
   "metadata": {},
   "source": [
    "## Give some use cases for Pandas, NumPy.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ceb63-c1e0-4faa-9d4d-24c857d74aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumPy provides various computing tools such as comprehensive mathematical functions, linear algebra routines. Pandas are used for handling, \n",
    "clearing of data, margining and joining of dataset, alignment and indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3af9d-63bb-4b89-8b38-3d0d27d617a9",
   "metadata": {},
   "source": [
    "## What libraries do you frequently use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c3329-0a63-4ab2-82b9-308ccbf6d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "Numpy.\n",
    "Scipy.\n",
    "Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f16707-b860-4c2d-89e3-de8026036781",
   "metadata": {},
   "source": [
    "##  What are the local and global variables in Python?a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10997a71-bf18-4304-b03a-2ffd98773440",
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables that are only referenced inside a function are implicitly global. If a variable is assigned a value anywhere within the function’s body, \n",
    "it’s assumed to be a local unless explicitly declared as global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d539d8-7c79-430d-83b4-0c8bb03e158f",
   "metadata": {},
   "source": [
    "## Mention five benefits of using Python?ity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f797cc-8ee3-4453-8327-07bcce39b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Easy to Read, Interpreted Language.\n",
    "Dynamically Typed with Improved Productivity.\n",
    "Free and Open-Source with Vast Libraries Support.\n",
    "Portability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e565180-c6d1-4cc9-a8f5-9699499bba27",
   "metadata": {},
   "source": [
    "## How do you create a dictionary in python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563595a5-451b-40e3-a467-843e2bbbd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "The dictionary can be created by placing a sequence of elements within curly {} braces, separated by ‘comma’. Dictionary holds a pair of values, \n",
    "one being the Key and the other corresponding pair element being its Key:value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2313881-9762-4ecd-996f-914e9739f088",
   "metadata": {},
   "source": [
    "##  How will you convert a string to an int in python? (Data type conversion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99056d8f-91e2-46de-bc11-41e1e719d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "To convert a string to integer in Python, use the int() function. This function takes two parameters: the initial string and the optional base to \n",
    "represent the data. Use the syntax print(int(“STR”)) to return the str as an int , or integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5a5ec-f80f-4347-826f-f2043c938178",
   "metadata": {},
   "source": [
    "## Can you illustrate a few commands for data cleaning?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ec5dd-1a32-4b6f-b026-997c0b8341a1",
   "metadata": {},
   "source": [
    "Data cleaning can be done using Numpy, Pandas using combining str methods, applymap function to clean entire data set, tidying up fields, \n",
    "renaming columns and skipping rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579cdfc-653a-4123-9d2b-df8d6166484f",
   "metadata": {},
   "source": [
    "##  How can you get information about the data frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de601aa1-0e8e-48cf-8268-b950ec024d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "The info() function is used to print a concise summary of a DataFrame. This method prints information about a DataFrame including the index \n",
    "dtype and column dtypes, non-null values and memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cba1e5-380e-4f96-8a4b-6471a5fc6dad",
   "metadata": {},
   "source": [
    "## What will be the output of the following code snippet? [I was given sample code]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ada4cd-d9d2-4ce7-b8c0-7bf8515aac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Look into the code snippet carefully and write the output by taking each code step into consideration. Explain to the interviewer in detail \n",
    "with the output of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed2b71-5fd1-4a97-adc0-10ba7a60fd71",
   "metadata": {},
   "source": [
    "# Infosys Data Science Interview Questtions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba578dc-1f75-4250-9ad3-1bd1d899788b",
   "metadata": {},
   "source": [
    "## \n",
    "1. What is Data Sciencee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfcd17-15ff-421e-b837-e10f17fc7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "An interdisciplinary field that constitutes various scientific processes, algorithms, tools, and machine learning techniques working to help \n",
    "find common patterns and gather sensible insights from the given raw input data using statistical and mathematical analysis is called Data Science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb85cf2-e84c-41db-8797-56ec449ef0d6",
   "metadata": {},
   "source": [
    "## Define the terms KPI, lift, model fitting, robustness and DOE.bles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0687830-2de2-4df9-a245-7bbfa4ea7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KPI: KPI stands for Key Performance Indicator that measures how well the business achieves its objectives.\n",
    "Lift: This is a performance measure of the target model measured against a random choice model. Lift indicates how good the model is at prediction \n",
    "versus if there was no model.\n",
    "Model fitting: This indicates how well the model under consideration fits given observations.\n",
    "Robustness: This represents the system’s capability to handle differences and variances effectively.\n",
    "DOE: stands for the design of experiments, which represents the task design aiming to describe and explain information variation under\n",
    "hypothesized conditions to reflect variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3730e563-7946-4f9b-b45c-f22309bcfe24",
   "metadata": {},
   "source": [
    "##  What is the difference between data analytics and data science?ion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5fa43-1722-40f5-bbe1-9a55740ec4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data science involves the task of transforming data by using various technical analysis methods to extract meaningful insights using which a data \n",
    "analyst can apply to their business scenarios.\n",
    "Data analytics deals with checking the existing hypothesis and information and answers questions for a better and effective business-related \n",
    "decision-making process.\n",
    "Data Science drives innovation by answering questions that build connections and answers for futuristic problems. Data analytics focuses on \n",
    "getting present meaning from existing historical context whereas data science focuses on predictive modeling.\n",
    "Data Science can be considered as a broad subject that makes use of various mathematical and scientific tools and algorithms for solving complex \n",
    "problems whereas data analytics can be considered as a specific field dealing with specific concentrated problems using fewer tools of statistics \n",
    "and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9c0d9-0a9d-46cd-be7a-8c74ae461070",
   "metadata": {},
   "source": [
    "# Google Data Scinece Interview Process For Recent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c54c7-a02b-4ad3-8587-0c5d7e5ef928",
   "metadata": {},
   "source": [
    "## How would you calculate the median in SQL?t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7d8db-a2eb-4140-acea-64d884d1a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are many ways to calculate the median in SQL, but one approach is to use a combination of the COUNT and RANK functions. First, count the total \n",
    "number of values in the column using COUNT, then rank each value using RANK (with an ORDER BY clause). Finally, select the value with a rank equal to \n",
    "half of the total count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74e4d5-45ac-4afe-90ed-bea1bd4b815e",
   "metadata": {},
   "source": [
    "## How would you handle missing values in a dataset using SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99546807-5442-4fb0-8977-5f70915cede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "One approach to handling missing values is to use the CASE statement. This allows you to set specific conditions for replacing missing values with \n",
    "another value, such as zero or the average of the column’s non-missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5c32cc-63fb-412f-a138-f6c5ffb5b300",
   "metadata": {},
   "source": [
    "## What’s the difference between using a UNION and a UNION ALL in SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c12d0a-b8d7-4b35-ab0c-8271f6b35b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "The main difference between using a UNION and a UNION ALL in SQL is that UNION automatically removes duplicate records from the results, \n",
    "whereas UNION ALL includes all duplicates. UNION performs a distinct operation on the results by default, which can be useful when you want to \n",
    "ensure that all returned rows are unique. On the other hand, UNION ALL does not perform any duplicate removal, \n",
    "making it faster in cases where you know the datasets do not overlap or when duplicate records are needed in the result set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d72a9-281e-4a88-b9a4-7f341f3d1da2",
   "metadata": {},
   "source": [
    "## How do you improve the performance of a Python script?ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970f6da-5110-4177-b3db-e6982c520859",
   "metadata": {},
   "outputs": [],
   "source": [
    "Improving the performance of a Python script can involve a variety of strategies, such as using more efficient data structures (e.g., using sets instead \n",
    "of lists for membership tests), leveraging list comprehensions and generator expressions, and utilizing built-in functions and libraries which are often\n",
    "optimized for performance. Additionally, the use of modules like NumPy for numerical tasks or implementing multiprocessing or \n",
    "threading to exploit parallelism can significantly enhance script performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef43e760-d179-41ad-9304-0b542a50b3ad",
   "metadata": {},
   "source": [
    "## How you would implement a machine learning model in Python?e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d2f312-ac86-48e3-9f7a-a982abd84f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implementing a machine learning model in Python typically begins with data preprocessing, including cleaning, normalization, and feature selection. \n",
    "Next, one would select a model based on the problem type (e.g., regression, classification) and use a library like scikit-learn to train the model \n",
    "on the preprocessed data. This involves splitting the data into training and test sets, fitting the model to the training data, and then evaluating \n",
    "its performance on the test set. Fine-tuning the model parameters may be required to optimize performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08449b7-8bba-4f85-9ec2-b8ac8254e9a2",
   "metadata": {},
   "source": [
    "## What are decorators in Python, and how would you use them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9bbdb-9d23-4007-a1bc-e576d1c9af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decorators in Python are a powerful and expressive tool for modifying the behavior of functions or methods. They allow you to wrap another function \n",
    "in order to extend its behavior without permanently modifying it. Decorators are commonly used for logging, access control, memorization, and code \n",
    "timing. To use a decorator, you simply precede the definition of a function with the decorator’s name preceded by the @ symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a834901-3f36-448b-b523-494a5f8b7e9f",
   "metadata": {},
   "source": [
    "## Explain the significance of the p-value in hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291881d4-3c3b-42e2-b396-b72758a2dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The p-value plays a critical role in hypothesis testing; it measures the probability of obtaining observed results, or results more extreme, \n",
    "assuming the null hypothesis is true. A p-value lower than a predetermined threshold (usually 0.05) indicates a statistically significant difference, \n",
    "leading researchers to reject the null hypothesis. This statistical measure helps in determining the significance of the results derived from a data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b197ac0-094f-4db4-95ab-597ec7624e60",
   "metadata": {},
   "source": [
    "## How would you use linear regression to predict future trends?s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffefbf-d5f6-463e-9dfb-06675774bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear regression is a foundational tool in predictive modeling, enabling the prediction of a dependent variable based on one or more independent \n",
    "variables. By establishing the best-fit linear relationship between the variables, it provides a formula that can be used to predict future values. \n",
    "This method is widely used in forecasting, where past data is analyzed to predict future occurrences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c658b4f-a6d4-413c-97a4-d21238bf24f2",
   "metadata": {},
   "source": [
    "## What is Bayes’ Theorem and how is it applied in data science?ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b77342-e15b-4aff-9032-624818d8cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes’ Theorem is utilized to update the probabilities for hypotheses as more evidence or information becomes available. It’s a vital component \n",
    "in the toolkit of a data scientist for predictive modeling and risk assessment. By incorporating prior knowledge, data scientists can refine their \n",
    "predictions and analyses, making Bayes’ Theorem critical for decision-making processes in data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab7c88-94d3-45f8-9bee-5b8d604856fd",
   "metadata": {},
   "source": [
    "## How can the Central Limit Theorem be used in data analysis?s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6e6b9-3f27-4ede-aa81-047879de43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Central Limit Theorem (CLT) is fundamental in data analysis as it allows for the approximation of the sampling distribution of the sample mean \n",
    "to be normal, regardless of the population’s distribution, provided the sample size is sufficiently large. This theorem underpins many \n",
    "statistical methods and enables analysts to make inferences about population parameters from sample statistics, hence its crucial role in data \n",
    "analysis efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91333439-258d-410a-8959-3f54906c71ff",
   "metadata": {},
   "source": [
    "## You are given a data set that contains information about when users click on ads. How would you use this data to optimize ad campaigns?I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db4091-6d01-4335-9edd-e1f0530216e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Utilizing user click data, you can analyze user preferences, engagement times, and the effectiveness of different ad creatives. \n",
    "By developing a predictive model or performing A/B testing, strategies to optimize ad placements, timings, and creatives can be devised, \n",
    "enhancing campaign performance and ROI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ef8d4-f906-466b-b27a-aba4f465ccdb",
   "metadata": {},
   "source": [
    "## You are given a data set that contains transaction data from an eCommerce website. How would you use this data to increase conversion rates?s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fa949-c75e-46ee-b5c7-8d6b8207f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyzing eCommerce transaction data provides insights into customer buying behavior, popular products, and potential bottlenecks in the sales funnel. \n",
    "By employing statistical modeling or machine learning, personalized recommendations, targeted promotions, and an optimized checkout process can be \n",
    "implemented to improve conversion rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2866768-c033-4fff-90db-1e14ec6d35d5",
   "metadata": {},
   "source": [
    "## Given a data set, how would you find the most important factors contributing to customer churn?s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a417eb6-950b-4ffc-9673-0916c4e6aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Identifying factors contributing to customer churn involves analyzing customer data for correlations and patterns related to churn. \n",
    "Techniques like decision trees, logistic regression, or gradient boosting can reveal significant predictors of churn, facilitating targeted \n",
    "retention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c708244-a74f-46b0-b2b5-357702bb6c2c",
   "metadata": {},
   "source": [
    "## How would you develop a pricing strategy for Friday night rides for a rideshare app?g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d1f88-b319-431e-bf55-b1447c1d5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "For an Uber-type app, developing a dynamic pricing model for Friday night rides involves considering factors like demand and supply, traffic patterns, \n",
    "events in the city, and historical data. Initially, a simple regression model can be used for baseline pricing. Over time, as more data becomes \n",
    "available, the pricing strategy could be refined using machine learning algorithms, like random forest or neural networks, to incorporate real-time \n",
    "data such as ride requests, weather conditions, and competitor pricing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972781b-43d4-4494-9e0a-f27c9c857bc5",
   "metadata": {},
   "source": [
    "## How would you investigate if teenagers are leaving Facebook because their parents are joining?s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849eafb-f17a-4354-a55a-072224918542",
   "metadata": {},
   "outputs": [],
   "source": [
    "To investigate whether teenagers are leaving Facebook due to parental presence, an analysis would involve combining data sets of user \n",
    "information (focusing on teenagers and their parents) and usage patterns. Using SQL to correlate teenager activity levels inversely with the \n",
    "increase in parent sign-ups could offer insights. A typical SQL query could merge user demographic data, parent-child linkage, and usage activity \n",
    "to form a foundational dataset for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a70f82-9481-4681-a8db-94747bc6f0ce",
   "metadata": {},
   "source": [
    "## How do you create a dashboard to monitor customer usage and engagement?t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9610576-9e32-48f4-9702-c42490bd6c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Creating a customer usage dashboard entails defining key engagement metrics like session length, visit frequency, and actions per visit. \n",
    "By segmenting these metrics over defined time periods (daily, weekly, etc.), businesses can glean insights into user behaviors and peak activities. \n",
    "Aggregating this data via SQL queries, the dashboard can guide strategies to enhance content delivery and user interaction to boost engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d021fe-fbf0-4fb5-98ec-9064a2b539f8",
   "metadata": {},
   "source": [
    "## How can customer satisfaction be measured using Google Maps data?t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5d1fb-d300-4ca4-8976-7839c9e4c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "To quantify customer satisfaction on Google Maps, an analytical approach involving sentiment analysis of reviews and statistical examination of rating\n",
    "trends is recommended. Exploring additional engagement metrics, such as repeat usage and interactions with app features, can provide a comprehensive \n",
    "view of user satisfaction levels and areas for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07541377-f1ac-4f55-a814-110298dba597",
   "metadata": {},
   "source": [
    "## What approach would you take to analyze usage patterns and improve engagement on Yelp?e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7229a4e-806f-4a0c-a48c-bd478c29a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "For a Yelp check-in app, understanding usage necessitates examining check-in patterns, reviews post-check-in, and visit frequency. Employing data \n",
    "mining to identify trends like peak check-in times and popular locations, and correlating check-ins with positive reviews, can highlight features \n",
    "driving engagement. Further, using machine learning techniques like clustering algorithms can segment users by behavior, facilitating targeted \n",
    "marketing efforts and feature development to enhance user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3608004-fb4d-4036-9622-94139bca65a5",
   "metadata": {},
   "source": [
    "## How would you develop a machine learning model to predict whether or not a customer will purchase a product?s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab699c4e-9871-4c77-b55e-1970cf070270",
   "metadata": {},
   "outputs": [],
   "source": [
    "To develop a machine learning model for predicting customer purchases, you’d start by collecting and preprocessing relevant data, such as past \n",
    "purchase history, customer demographics, and engagement metrics. Training a model on this dataset with a binary outcome (purchase or not) enables \n",
    "the identification of patterns and factors influencing purchase decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b98218-ed35-47aa-a2cd-dedf4e6668f2",
   "metadata": {},
   "source": [
    "## What is a decision tree?t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f18faf4-7317-40c3-8a82-c8d21fed2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "A decision tree is a type of machine learning model used to predict the value of a target variable by splitting the dataset into smaller subsets until\n",
    "each subset contains only one data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848bc8e9-1af3-4ab0-a242-0466aa753665",
   "metadata": {},
   "source": [
    "## How would you use a decision tree to predict whether or not a customer will churn?g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f0b3b-9a4c-4ae9-84a2-d09030e01d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "To predict customer churn using a decision tree, you would need to train the model with data on customers who have previously churned. This involves\n",
    "analyzing customer behavior and attributes to identify patterns. Once trained, the model can predict the likelihood of future customers churning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf220ad-fd78-423e-bae0-b5b970ec87ce",
   "metadata": {},
   "source": [
    "## What is gradient boosting?n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363fdfb-6a17-41c4-ab5c-c556d81fccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient boosting is a machine learning algorithm designed to improve accuracy by training a series of weak models sequentially. Each model corrects \n",
    "errors made by the previous ones, combining their predictions to form a more accurate final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9ac3e-c255-4b71-b35e-69bf3f26d841",
   "metadata": {},
   "source": [
    "## How would you use gradient boosting to improve the accuracy of a machine learning model?l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f83915-b76c-481b-b4e5-1c4c30e70280",
   "metadata": {},
   "outputs": [],
   "source": [
    "Improving a model’s accuracy with gradient boosting involves training weak models on different data subsets and iteratively adjusting them based on \n",
    "the accuracy of the previous model’s predictions. This process helps in reducing bias and variance, leading to a more accurate and robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6e752-169f-4052-8ab7-14cfe131922e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2eb18-bbee-41d5-bae1-1cd6b856261e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad7451-f11e-43c8-91d4-37cb020b5c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f568b60-39ef-4c37-b440-c70cfce705ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9e5a7-bc31-498e-ae2e-d771f761a337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5237ebe-6be2-4c3a-bf45-6c0d1b47ce79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179fd98-0a97-4535-b1b2-2d2ec3116b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5721319-a53d-4a86-b207-14806cf181c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e4e54-e772-4ffc-aacb-c8ae7abb591b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2291ced-70c0-4266-bbb1-f0b1db5a3f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befaa26a-4504-4ff6-952b-9774a485c256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63164c-e10d-4397-82f2-4f5fb999856d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9129b1-86b0-4d36-9485-78ad0a38540e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d61da-fbbe-4839-8711-e6065851337c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba75ba9-43a0-4537-a193-bfdc35e99c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eec31d-f6a8-4665-8bc0-25c22afde1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b9daa-aed7-4b63-9da8-d2230347ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f56c6-cc24-44e0-b7dc-c3f1ca9fadfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e73022-f263-4dc3-a813-60bf7456991e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f662c58-f0a1-4093-a9b6-6929e377a9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8032e-b053-4a60-9613-2621124374f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b180e5-792c-4931-b519-ec5029fa1e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae38e5-2c32-48de-bad4-168f00134d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3408f-487d-4af0-bc74-a7d77c8df6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e4939-bb8c-4c87-9f4b-d040ca52448a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce4ffb-9d38-4e4b-80ac-744a91957f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8ca12-abe2-4a5f-8a47-8817164a1e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d3a6c-b961-4f28-bdea-fd05d0b87e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271da8d-a3b1-4aa5-8c41-fe0601e2e020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebc5c0-5ac8-4ab7-a452-7a0efffccefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79936954-08bc-43a4-ac67-1f66d3bd20da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6549a6-3ba2-4cdd-b0ff-4448e0506f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b20c78-cac9-42e7-aeca-69c6447676cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db7261-907e-4cfa-8664-6333f7bd857c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8ba2d-db35-4196-ad8d-535f36d15d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396272be-23f0-48b6-a2e6-c6fedd23666c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc335f3-c3e5-4700-9f18-eabb03227a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced228f8-6518-42f0-a412-c40efeb52b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485b7e1-aaab-448a-9e08-f7df4b9c8fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d358019-d023-4464-8ed8-ee36812c661b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
